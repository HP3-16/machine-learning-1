{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of weight initialization:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Constant\n",
    "b. Uniform\n",
    "c. Normal\n",
    "d. LeCun uniform & normal\n",
    "e. Glorot/Xavier - uniform & normal\n",
    "f. He - uniform & normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "W1 = np.zeros((64,32))\n",
    "W2 = np.ones((64,32))\n",
    "W3 = np.ones((64,32)) * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uniform\n",
    "W_uniform = np.random.uniform(low=-1,high=1,size=(64,32))\n",
    "#Normal\n",
    "W_normal = np.random.normal(0.0, 0.5,size=(64,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeCun uniform & normal\n",
    "#uniform - default for torch\n",
    "F_in = 64 #no. of inputs to the layer\n",
    "F_out = 32 #no. of outputs from the layer\n",
    "limit = np.sqrt(3/float(F_in))\n",
    "W_LeCun_uniform = np.random.uniform(low=-limit,high=limit,size=(F_in,F_out))\n",
    "#normal - truncated formulation used in Keras/Tensorflow\n",
    "F_in = 64 #no. of inputs to the layer\n",
    "F_out = 32 #no. of outputs from the layer\n",
    "limit = np.sqrt(1/float(F_in))\n",
    "W_LeCun_normal = np.random.normal(0.0,limit,size=(F_in,F_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glorot / Xavier\n",
    "#Default initialization in Keras/Tensorflow\n",
    "F_in = 64 #no. of inputs to the layer\n",
    "F_out = 32 #no. of outputs from the layer\n",
    "limit = np.sqrt(2/float(F_in+F_out))\n",
    "W_GX_normal = np.random.normal(0.0,limit,size=(F_in,F_out))\n",
    "\n",
    "#uniform - more stricter limit\n",
    "F_in = 64 #no. of inputs to the layer\n",
    "F_out = 32 #no. of outputs from the layer\n",
    "limit = np.sqrt(6/float(F_in+F_out))\n",
    "W_GX_uniform = np.random.uniform(low=-limit,high=limit,size=(F_in,F_out))\n",
    "\n",
    "#best practise - used for non-residual neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#He et al. / Kaiming /MSRA uniform normal\n",
    "#used for deep residual neural networks\n",
    "#used with variations of ReLus\n",
    "F_in = 64 #no. of inputs to the layer\n",
    "F_out = 32 #no. of outputs from the layer\n",
    "limit = np.sqrt(6/float(F_in))\n",
    "W_He_uniform = np.random.uniform(low=-limit,high=limit,size=(F_in,F_out))\n",
    "\n",
    "F_in = 64 #no. of inputs to the layer\n",
    "F_out = 32 #no. of outputs from the layer\n",
    "limit = np.sqrt(2/float(F_in))\n",
    "W_He_normal = np.random.normal(0.0,limit,size=(F_in,F_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
